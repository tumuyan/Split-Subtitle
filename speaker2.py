import argparse
import sys
from pathlib import Path
import pysubs2
from pyannote.audio import Pipeline
import torch
from tqdm import tqdm

def find_max_overlap_speaker(sub_start, sub_end, diarization):
    max_overlap = 0
    best_speaker = "Unknown" # é»˜è®¤å€¼
    
    for segment, _, speaker in diarization.itertracks(yield_label=True):
        overlap_start = max(sub_start, segment.start)
        overlap_end = min(sub_end, segment.end)
        overlap_duration = overlap_end - overlap_start
        
        if overlap_duration > max_overlap:
            max_overlap = overlap_duration
            best_speaker = speaker
            
    return best_speaker

def main():
    parser = argparse.ArgumentParser(
        description="ä½¿ç”¨æœ¬åœ°çš„ pyannote.audio æ¨¡å‹è¿›è¡Œè¯´è¯äººè¯†åˆ«å¹¶ä¸å­—å¹•å¯¹é½ã€‚",
        formatter_class=argparse.RawTextHelpFormatter
    )
    parser.add_argument("subtitle_file", type=Path, help="è¾“å…¥çš„å­—å¹•æ–‡ä»¶è·¯å¾„ (srt æˆ– ass)ã€‚")
    parser.add_argument("media_file", type=Path, help="è¾“å…¥çš„è§†é¢‘æˆ–éŸ³é¢‘æ–‡ä»¶è·¯å¾„ã€‚")
    parser.add_argument("-o", "--output_file", type=Path, help="è¾“å‡ºå­—å¹•æ–‡ä»¶è·¯å¾„ã€‚")
    parser.add_argument(
        "--model_dir", type=Path, default="./diarization_model",
        help="åŒ…å« pyannote æ¨¡å‹çš„æœ¬åœ°æ–‡ä»¶å¤¹è·¯å¾„ã€‚"
    )
    
    if len(sys.argv) == 1:
        parser.print_help(sys.stderr)
        sys.exit(1)
        
    args = parser.parse_args()
    
    output_path = args.output_file or args.subtitle_file.with_name(f"{args.subtitle_file.stem}.diarized_local{args.subtitle_file.suffix}")

    # --- æ–°å¢/ä¿®æ”¹éƒ¨åˆ†ï¼šæ ¹æ®è¾“å‡ºæ–‡ä»¶æ‰©å±•ååˆ¤æ–­æ ¼å¼ ---
    # å†³å®šè¾“å‡ºæ ¼å¼æ˜¯ASSè¿˜æ˜¯å…¶ä»–æ ¼å¼ï¼Œè¿™ä¼šå½±å“è¯´è¯äººä¿¡æ¯çš„å†™å…¥æ–¹å¼
    is_output_ass = output_path.suffix.lower() in ['.ass', '.ssa']
    
    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶å¤¹å’Œé…ç½®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    config_path = args.model_dir / "config.yaml"
    if not config_path.is_file():
        print(f"âŒ é”™è¯¯ï¼šåœ¨ '{args.model_dir}' æ–‡ä»¶å¤¹ä¸­æ‰¾ä¸åˆ° 'config.yaml'ã€‚")
        print("è¯·ç¡®ä¿æ‚¨å·²æˆåŠŸä¸‹è½½æ¨¡å‹ï¼Œå¹¶ä¸” --model_dir å‚æ•°æŒ‡å‘äº†æ­£ç¡®çš„è·¯å¾„ã€‚")
        sys.exit(1)

    # --- 1. ä»æœ¬åœ°è·¯å¾„åˆå§‹åŒ– Pipeline ---
    print(f"ğŸ”Š æ­£åœ¨ä»æœ¬åœ°è·¯å¾„ '{args.model_dir}' åŠ è½½æ¨¡å‹...")
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"å°†ä½¿ç”¨ '{device}' è®¾å¤‡è¿›è¡Œå¤„ç†ã€‚")
    
    try:
        pipeline = Pipeline.from_pretrained(config_path)
        pipeline.to(torch.device(device))
    except Exception as e:
        print(f"\nâŒ ä»æœ¬åœ°åŠ è½½æ¨¡å‹å¤±è´¥: {e}")
        sys.exit(1)

    # --- 2. æ‰§è¡Œè¯´è¯äººæ—¥å¿— ---
    print(f"ğŸ”„ æ­£åœ¨å¤„ç†åª’ä½“æ–‡ä»¶: {args.media_file}...")
    print("è¿™å¯èƒ½éœ€è¦å¾ˆé•¿æ—¶é—´ï¼Œå–å†³äºæ–‡ä»¶é•¿åº¦å’Œæ‚¨çš„ç¡¬ä»¶...")
    try:
        diarization = pipeline(str(args.media_file))
        print("âœ… è¯´è¯äººæ—¥å¿—å¤„ç†å®Œæˆï¼")
    except Exception as e:
        print(f"\nâŒ å¤„ç†åª’ä½“æ–‡ä»¶æ—¶å‡ºé”™: {e}")
        sys.exit(1)

    # --- 3. åŠ è½½å­—å¹•å¹¶å¯¹é½ ---
    print(f"ğŸ“ æ­£åœ¨åŠ è½½å­—å¹•æ–‡ä»¶: {args.subtitle_file} å¹¶è¿›è¡Œå¯¹é½...")
    subs = pysubs2.load(str(args.subtitle_file), encoding="utf-8")
    
    # --- å…³é”®ä¿®æ”¹ï¼šä½¿ç”¨ is_output_ass è¿›è¡Œåˆ¤æ–­ ---
    for sub_line in tqdm(subs, desc="å¯¹é½å­—å¹•"):
        sub_start_sec = sub_line.start / 1000.0
        sub_end_sec = sub_line.end / 1000.0
        
        speaker_id = find_max_overlap_speaker(sub_start_sec, sub_end_sec, diarization)
        
        if speaker_id != "Unknown":
            simple_id = speaker_id.split('_')[1].lstrip('0')
            speaker_name = f"Speaker {simple_id}"

            # æ ¹æ®è¾“å‡ºæ ¼å¼å†³å®šå¦‚ä½•å†™å…¥è¯´è¯äºº
            if is_output_ass:
                # å¯¹äº ASS/SSA æ ¼å¼ï¼Œå¡«å…… Name (Actor) å­—æ®µ
                if not sub_line.name: # åªæœ‰å½“ Name å­—æ®µä¸ºç©ºæ—¶æ‰å¡«å……
                    sub_line.name = speaker_name
            else:
                # å¯¹äº SRT ç­‰å…¶ä»–æ ¼å¼ï¼Œå°†è¯´è¯äººä½œä¸ºå‰ç¼€æ·»åŠ åˆ°æ–‡æœ¬ä¸­
                sub_line.text = f"{speaker_name}: {sub_line.text}"

    # --- 4. ä¿å­˜ç»“æœ ---
    subs.save(str(output_path), encoding="utf-8")
    
    print("\nğŸ‰ å…¨éƒ¨å®Œæˆï¼")
    print(f"è¾“å‡ºæ–‡ä»¶å·²ä¿å­˜è‡³: {output_path}")

if __name__ == "__main__":
    main()